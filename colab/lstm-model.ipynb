{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Keystroke Dynamics - BiLSTM + Embedding Model Training\n",
                "\n",
                "This notebook implements the training pipeline for a Multi-Input BiLSTM model used for keystroke dynamics authentication.\n",
                "\n",
                "### Architecture:\n",
                "1.  **Input A (Timing)**: `(N, 50, 5)` Float32 - Dwell, Flight, Latency, etc.\n",
                "2.  **Input B (Key ID)**: `(N, 50)` Int32 - Character codes for Embedding.\n",
                "3.  **Layers**: Masking -> BiLSTM (Timing) + Embedding -> LSTM (Keys) -> Concatenate -> Dense."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "import numpy as np\n",
                "import tensorflow as tf\n",
                "from tensorflow.keras import layers, models, regularizers, optimizers, callbacks\n",
                "from pathlib import Path\n",
                "import glob\n",
                "import random\n",
                "\n",
                "print(\"TensorFlow Version:\", tf.__version__)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Robust Key Encoding (Shared Logic)\n",
                "\n",
                "This logic MUST match `web-app/app/services.py` exactly to ensure consistent inputs."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def get_stable_key_id(key: str) -> int:\n",
                "    if len(key) == 1:\n",
                "        # Shift ASCII by 2 to reserve 0 and 1\n",
                "        return ord(key) + 2\n",
                "    \n",
                "    special_map = {\n",
                "        \"Backspace\": 8 + 2,\n",
                "        \"Tab\": 9 + 2,\n",
                "        \"Enter\": 13 + 2,\n",
                "        \"Shift\": 16 + 2,\n",
                "        \"Control\": 17 + 2,\n",
                "        \"Alt\": 18 + 2,\n",
                "        \"CapsLock\": 20 + 2,\n",
                "        \"Escape\": 27 + 2,\n",
                "        \"Space\": 32 + 2,\n",
                "        \"PageUp\": 33 + 2,\n",
                "        \"PageDown\": 34 + 2,\n",
                "        \"End\": 35 + 2,\n",
                "        \"Home\": 36 + 2,\n",
                "        \"ArrowLeft\": 37 + 2,\n",
                "        \"ArrowUp\": 38 + 2,\n",
                "        \"ArrowRight\": 39 + 2,\n",
                "        \"ArrowDown\": 40 + 2,\n",
                "        \"Insert\": 45 + 2,\n",
                "        \"Delete\": 127 + 2\n",
                "    }\n",
                "    return special_map.get(key, 1) # 1 = UNK\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Data Loading & Sequence Generation (Clean Split)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "TARGET_LENGTH = 50\n",
                "\n",
                "def process_json_file(filepath):\n",
                "    with open(filepath, 'r', encoding='utf-8') as f:\n",
                "        data = json.load(f)\n",
                "    \n",
                "    keystrokes = data.get('keystrokes', [])\n",
                "    username = data.get('username')\n",
                "    \n",
                "    if not keystrokes:\n",
                "        return None, None, None\n",
                "\n",
                "    # Feature Engineering Constants\n",
                "    TIME_SCALE = 7.0\n",
                "    MAX_LATENCY = 3000.0\n",
                "\n",
                "    # Separate lists for the two inputs\n",
                "    sequence_time = []\n",
                "    sequence_keys = []\n",
                "    \n",
                "    keydown_events = {}\n",
                "    previous_keyup_time = None\n",
                "    previous_keydown_time = None\n",
                "\n",
                "    for idx, event in enumerate(keystrokes):\n",
                "        key = event['key']\n",
                "        event_type = event['event_type']\n",
                "        timestamp = event['timestamp']\n",
                "\n",
                "        # -- Time Feature Calculation Logic --\n",
                "        if event_type == \"keydown\":\n",
                "            keydown_events[key] = timestamp\n",
                "            previous_keydown_time = timestamp\n",
                "            if key in {\"Backspace\", \"Shift\"}: continue\n",
                "\n",
                "        elif event_type == \"keyup\":\n",
                "            if key in {\"Shift\", \"Backspace\"}:\n",
                "                if key in keydown_events: del keydown_events[key]\n",
                "                continue\n",
                "\n",
                "            dwell_time = 0.0\n",
                "            keydown_time = keydown_events.get(key)\n",
                "            if keydown_time:\n",
                "                dwell_time = timestamp - keydown_time\n",
                "                del keydown_events[key]\n",
                "            \n",
                "            flight_time = (keydown_time - previous_keyup_time) if (previous_keyup_time and keydown_time) else 0.0\n",
                "            inter_key_delay = (timestamp - keystrokes[idx - 1]['timestamp']) if idx > 0 else 0.0\n",
                "\n",
                "            # Clamping (Outlier Removal)\n",
                "            dwell_time = min(dwell_time, MAX_LATENCY)\n",
                "            flight_time = min(flight_time, MAX_LATENCY)\n",
                "            inter_key_delay = min(inter_key_delay, MAX_LATENCY)\n",
                "\n",
                "            # Log1p Normalization using TIME_SCALE\n",
                "            norm_dwell = np.log1p(dwell_time) / TIME_SCALE\n",
                "            norm_flight = np.log1p(flight_time) / TIME_SCALE if flight_time > 0 else 0.0\n",
                "            norm_delay = np.log1p(inter_key_delay) / TIME_SCALE\n",
                "            \n",
                "            # Base features: [Dwell, Flight, Delay]\n",
                "            time_vector = [float(norm_dwell), float(norm_flight), float(norm_delay)]\n",
                "            \n",
                "            # Feature 4: Pressure (Simulated)\n",
                "            time_vector.append(min(dwell_time / 200.0, 1.0))\n",
                "            \n",
                "            # Feature 5: Down-Down Latency\n",
                "            if previous_keydown_time and keydown_time:\n",
                "                dd_lat = keydown_time - previous_keydown_time\n",
                "                dd_lat = min(dd_lat, MAX_LATENCY) # Clamp\n",
                "                time_vector.append(np.log1p(dd_lat) / TIME_SCALE)\n",
                "            else:\n",
                "                time_vector.append(0.0)\n",
                "\n",
                "            # KEY ID stored separately\n",
                "            key_id = get_stable_key_id(key)\n",
                "\n",
                "            sequence_time.append(time_vector)\n",
                "            sequence_keys.append(key_id)\n",
                "            \n",
                "            previous_keyup_time = timestamp\n",
                "\n",
                "    # Sliding Window Logic for BOTH lists\n",
                "    final_time_sequences = []\n",
                "    final_key_sequences = []\n",
                "\n",
                "    def get_padded_window(seq, is_key=False):\n",
                "        res = list(seq)\n",
                "        if len(res) < TARGET_LENGTH:\n",
                "            pad_val = 0 if is_key else [0.0] * 5\n",
                "            while len(res) < TARGET_LENGTH:\n",
                "                res.append(pad_val)\n",
                "        return res[:TARGET_LENGTH]\n",
                "\n",
                "    if len(sequence_time) < TARGET_LENGTH:\n",
                "        final_time_sequences.append(get_padded_window(sequence_time, is_key=False))\n",
                "        final_key_sequences.append(get_padded_window(sequence_keys, is_key=True))\n",
                "    else:\n",
                "        step = TARGET_LENGTH // 2\n",
                "        for i in range(0, len(sequence_time) - TARGET_LENGTH + 1, step):\n",
                "            final_time_sequences.append(sequence_time[i : i + TARGET_LENGTH])\n",
                "            final_key_sequences.append(sequence_keys[i : i + TARGET_LENGTH])\n",
                "\n",
                "        remaining = len(sequence_time)\n",
                "        if remaining > TARGET_LENGTH and (remaining - TARGET_LENGTH) % step != 0:\n",
                "             final_time_sequences.append(sequence_time[-TARGET_LENGTH:])\n",
                "             final_key_sequences.append(sequence_keys[-TARGET_LENGTH:])\n",
                "    \n",
                "    return np.array(final_time_sequences), np.array(final_key_sequences), username\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Load All Data"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Set path to your raw json files\n",
                "# Adjust this path to match your Colab or Local structure\n",
                "# If using Colab, upload files to a folder named 'keystroke_data'\n",
                "data_path = Path(\"../web-app/keystroke_data\") \n",
                "json_files = list(data_path.rglob(\"*.json\"))\n",
                "\n",
                "all_X_time = []\n",
                "all_X_key = []\n",
                "all_y = []\n",
                "\n",
                "label_map = {}\n",
                "current_label = 0\n",
                "\n",
                "for f in json_files:\n",
                "    xt, xk, user = process_json_file(f)\n",
                "    if xt is not None and user is not None:\n",
                "        if user not in label_map:\n",
                "            label_map[user] = current_label\n",
                "            current_label += 1\n",
                "        \n",
                "        label_id = label_map[user]\n",
                "        \n",
                "        for i in range(len(xt)):\n",
                "            all_X_time.append(xt[i])\n",
                "            all_X_key.append(xk[i])\n",
                "            all_y.append(label_id)\n",
                "\n",
                "X_time_train = np.array(all_X_time, dtype=np.float32)\n",
                "X_key_train = np.array(all_X_key, dtype=np.int32)\n",
                "y_train = np.array(all_y, dtype=np.int32)\n",
                "\n",
                "print(\"Classes:\", label_map)\n",
                "print(\"X_time shape:\", X_time_train.shape)\n",
                "print(\"X_key shape:\", X_key_train.shape)\n",
                "print(\"y shape:\", y_train.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Build Multi-Input Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Inputs\n",
                "input_time = layers.Input(shape=(50, 5), name=\"input_time\")\n",
                "input_key = layers.Input(shape=(50,), dtype=\"int32\", name=\"input_key\")\n",
                "\n",
                "# Branch A: Timing (Float)\n",
                "# Masking for 0.0 values (padding)\n",
                "masked_time = layers.Masking(mask_value=0.0)(input_time)\n",
                "bilstm_time = layers.Bidirectional(layers.LSTM(64, return_sequences=False))(masked_time)\n",
                "bilstm_time = layers.Dropout(0.3)(bilstm_time)\n",
                "\n",
                "# Branch B: Key IDs (Embedding)\n",
                "# Vocab Size = 1000 (Safe for Turkish/Unicode), Dim = 16\n",
                "embedding = layers.Embedding(input_dim=1000, output_dim=16, mask_zero=True)(input_key)\n",
                "lstm_key = layers.LSTM(32, return_sequences=False)(embedding)\n",
                "lstm_key = layers.Dropout(0.3)(lstm_key)\n",
                "\n",
                "# Merge\n",
                "merged = layers.Concatenate()([bilstm_time, lstm_key])\n",
                "dense = layers.Dense(32, activation=\"relu\")(merged)\n",
                "\n",
                "# Output\n",
                "num_classes = len(label_map)\n",
                "if num_classes == 2:\n",
                "    output = layers.Dense(1, activation=\"sigmoid\")(dense)\n",
                "    loss = \"binary_crossentropy\"\n",
                "else:\n",
                "    output = layers.Dense(num_classes, activation=\"softmax\")(dense)\n",
                "    loss = \"sparse_categorical_crossentropy\"\n",
                "\n",
                "model = models.Model(inputs=[input_time, input_key], outputs=output)\n",
                "\n",
                "model.compile(optimizer=\"adam\", loss=loss, metrics=[\"accuracy\"])\n",
                "model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 5. Train"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "history = model.fit(\n",
                "    [X_time_train, X_key_train],\n",
                "    y_train,\n",
                "    epochs=50,\n",
                "    batch_size=16,\n",
                "    validation_split=0.2\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 6. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model.save(\"keystroke_lstm_model.h5\")\n",
                "print(\"Model saved as keystroke_lstm_model.h5\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}